{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9e0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3564bdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/rasterstats/io.py:335: NodataWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       NAME_2  Sum_of_Lights\n",
      "0             Nicobar Islands          401.0\n",
      "1    North and Middle Andaman         1586.0\n",
      "2               South Andaman         4499.0\n",
      "3                   Anantapur       117838.0\n",
      "4                    Chittoor       116679.0\n",
      "..                        ...            ...\n",
      "671        Pashchim Medinipur        38347.0\n",
      "672           Purba Medinipur        31000.0\n",
      "673                  Puruliya        20738.0\n",
      "674         South 24 Parganas        48328.0\n",
      "675            Uttar Dinajpur        18640.0\n",
      "\n",
      "[676 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/09/48yq1dds6xl7b16f3b68lvmr0000gn/T/ipykernel_21613/4228089434.py:17: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  districts.to_file(\"district_sums.shp\")\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights' to 'Sum_of_Lig'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "# Load the district-level shapefile (gadm41_IND_2.shp)\n",
    "# Make sure you provide the correct path to the shapefile\n",
    "districts = gpd.read_file('gadm41_IND_2.shp')\n",
    "\n",
    "# Open the Nighttime Lights GeoTIFF file\n",
    "with rasterio.open('Harmonized_DN_NTL_2008_calDMSP.tif') as src:\n",
    "    # Perform zonal statistics (sum of light) district-wise\n",
    "    stats = zonal_stats(districts, src.read(1), affine=src.transform, stats=\"sum\")\n",
    "\n",
    "# Add SOL results to the GeoDataFrame\n",
    "districts['Sum_of_Lights'] = [stat['sum'] for stat in stats]\n",
    "\n",
    "# Display or save the results\n",
    "print(districts[['NAME_2', 'Sum_of_Lights']])  # 'NAME_2' is typically the column for district names\n",
    "\n",
    "# Optionally, export to a new shapefile or CSV\n",
    "districts.to_file(\"district_sums.shp\")\n",
    "districts[['NAME_2', 'Sum_of_Lights']].to_csv(\"district_SOL_2008.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888ed061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOL for 1992 calculated and saved to district_SOL_1992.csv\n",
      "SOL for 1993 calculated and saved to district_SOL_1993.csv\n",
      "SOL for 1994 calculated and saved to district_SOL_1994.csv\n",
      "SOL for 1995 calculated and saved to district_SOL_1995.csv\n",
      "SOL for 1996 calculated and saved to district_SOL_1996.csv\n",
      "SOL for 1997 calculated and saved to district_SOL_1997.csv\n",
      "SOL for 1998 calculated and saved to district_SOL_1998.csv\n",
      "SOL for 1999 calculated and saved to district_SOL_1999.csv\n",
      "SOL for 2000 calculated and saved to district_SOL_2000.csv\n",
      "SOL for 2001 calculated and saved to district_SOL_2001.csv\n",
      "SOL for 2002 calculated and saved to district_SOL_2002.csv\n",
      "SOL for 2003 calculated and saved to district_SOL_2003.csv\n",
      "SOL for 2004 calculated and saved to district_SOL_2004.csv\n",
      "SOL for 2005 calculated and saved to district_SOL_2005.csv\n",
      "SOL for 2006 calculated and saved to district_SOL_2006.csv\n",
      "SOL for 2007 calculated and saved to district_SOL_2007.csv\n",
      "SOL for 2008 calculated and saved to district_SOL_2008.csv\n",
      "SOL for 2009 calculated and saved to district_SOL_2009.csv\n",
      "SOL for 2010 calculated and saved to district_SOL_2010.csv\n",
      "SOL for 2011 calculated and saved to district_SOL_2011.csv\n",
      "SOL for 2012 calculated and saved to district_SOL_2012.csv\n",
      "SOL for 2013 calculated and saved to district_SOL_2013.csv\n",
      "SOL for 2014 calculated and saved to district_SOL_2014.csv\n",
      "SOL for 2015 calculated and saved to district_SOL_2015.csv\n",
      "SOL for 2016 calculated and saved to district_SOL_2016.csv\n",
      "SOL for 2017 calculated and saved to district_SOL_2017.csv\n",
      "SOL for 2018 calculated and saved to district_SOL_2018.csv\n",
      "SOL for 2019 calculated and saved to district_SOL_2019.csv\n",
      "SOL for 2020 calculated and saved to district_SOL_2020.csv\n",
      "SOL for 2021 calculated and saved to district_SOL_2021.csv\n",
      "SOL for 2022 calculated and saved to district_SOL_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/09/48yq1dds6xl7b16f3b68lvmr0000gn/T/ipykernel_21613/3349643528.py:66: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  districts.to_file(\"district_sums_all_years.shp\")\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1992' to 'Sum_of_Lig'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1993' to 'Sum_of_L_1'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1994' to 'Sum_of_L_2'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1995' to 'Sum_of_L_3'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1996' to 'Sum_of_L_4'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1997' to 'Sum_of_L_5'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1998' to 'Sum_of_L_6'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_1999' to 'Sum_of_L_7'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2000' to 'Sum_of_L_8'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2001' to 'Sum_of_L_9'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2002' to 'Sum_of_L10'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2003' to 'Sum_of_L11'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2004' to 'Sum_of_L12'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2005' to 'Sum_of_L13'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2006' to 'Sum_of_L14'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2007' to 'Sum_of_L15'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2008' to 'Sum_of_L16'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2009' to 'Sum_of_L17'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2010' to 'Sum_of_L18'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2011' to 'Sum_of_L19'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2012' to 'Sum_of_L20'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2013' to 'Sum_of_L21'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2014' to 'Sum_of_L22'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2015' to 'Sum_of_L23'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2016' to 'Sum_of_L24'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2017' to 'Sum_of_L25'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2018' to 'Sum_of_L26'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2019' to 'Sum_of_L27'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2020' to 'Sum_of_L28'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2021' to 'Sum_of_L29'\n",
      "  ogr_write(\n",
      "/Users/sanketjagtap/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Sum_of_Lights_2022' to 'Sum_of_L30'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "import os\n",
    "\n",
    "# Load the district-level shapefile (gadm41_IND_2.shp)\n",
    "# Make sure you provide the correct path to the shapefile\n",
    "districts = gpd.read_file('gadm41_IND_2.shp')\n",
    "\n",
    "# List of .tif files (from 1992 to 2022)\n",
    "tif_files = [\n",
    "    'Harmonized_DN_NTL_1992_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_1993_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_1994_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_1995_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_1996_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_1997_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_1998_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_1999_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2000_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2001_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2002_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2003_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2004_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2005_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2006_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2007_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2008_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2009_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2010_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2011_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2012_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2013_calDMSP.tif',\n",
    "    'Harmonized_DN_NTL_2014_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2015_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2016_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2017_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2018_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2019_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2020_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2021_simVIIRS.tif',\n",
    "    'Harmonized_DN_NTL_2022_simVIIRS.tif'\n",
    "]\n",
    "\n",
    "# Loop over each .tif file to calculate SOL district-wise\n",
    "for tif_file in tif_files:\n",
    "    # Extract the year from the filename (assuming the year is part of the filename)\n",
    "    # Year is the 3rd part in the filename (e.g., Harmonized_DN_NTL_1992_calDMSP.tif)\n",
    "    year = os.path.basename(tif_file).split('_')[3][:4]\n",
    "\n",
    "    # Open the corresponding Nighttime Lights GeoTIFF file\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        # Perform zonal statistics (sum of light) district-wise\n",
    "        stats = zonal_stats(districts, src.read(1), affine=src.transform, stats=\"sum\")\n",
    "\n",
    "    # Add SOL results for this year to the GeoDataFrame\n",
    "    districts[f'Sum_of_Lights_{year}'] = [stat['sum'] for stat in stats]\n",
    "\n",
    "    # Save the results to a CSV file for this year\n",
    "    output_csv = f'district_SOL_{year}.csv'\n",
    "    districts[['NAME_2', f'Sum_of_Lights_{year}']].to_csv(output_csv, index=True)\n",
    "\n",
    "    print(f'SOL for {year} calculated and saved to {output_csv}')\n",
    "\n",
    "# Optionally, save the final results to a shapefile with all years included\n",
    "districts.to_file(\"district_sums_all_years.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9a4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of values for 1992: 7984301.0\n",
      "Sum of values for 1993: 9239260.0\n",
      "Sum of values for 1994: 9275676.0\n",
      "Sum of values for 1995: 11900405.0\n",
      "Sum of values for 1996: 12285192.0\n",
      "Sum of values for 1997: 11646200.0\n",
      "Sum of values for 1998: 13413220.0\n",
      "Sum of values for 1999: 13756789.0\n",
      "Sum of values for 2000: 14938944.0\n",
      "Sum of values for 2001: 15188277.0\n",
      "Sum of values for 2002: 15512560.0\n",
      "Sum of values for 2003: 14436738.0\n",
      "Sum of values for 2004: 16643454.0\n",
      "Sum of values for 2005: 15363533.0\n",
      "Sum of values for 2006: 14054413.0\n",
      "Sum of values for 2007: 17363542.0\n",
      "Sum of values for 2008: 16494378.0\n",
      "Sum of values for 2009: 17972270.0\n",
      "Sum of values for 2010: 17688661.0\n",
      "Sum of values for 2011: 18773274.0\n",
      "Sum of values for 2012: 20756246.0\n",
      "Sum of values for 2013: 20462196.0\n",
      "Sum of values for 2014: 31386182.0\n",
      "Sum of values for 2015: 33098609.0\n",
      "Sum of values for 2016: 31616158.0\n",
      "Sum of values for 2017: 39389994.0\n",
      "Sum of values for 2018: 40069286.0\n",
      "Sum of values for 2019: 42240367.0\n",
      "Sum of values for 2020: 39742451.0\n",
      "Sum of values for 2021: 42318903.0\n",
      "Sum of values for 2022: 45347730.0\n",
      "Sum of lights for all years saved to 'sum_of_SOL_all_years.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your CSV files\n",
    "csv_folder = 'SOL data from 1992 to 2022 csv Indexed'\n",
    "\n",
    "# List of CSV files (from 1992 to 2022) in that folder\n",
    "csv_files = [\n",
    "    'district_SOL_1992.csv',\n",
    "    'district_SOL_1993.csv',\n",
    "    'district_SOL_1994.csv',\n",
    "    'district_SOL_1995.csv',\n",
    "    'district_SOL_1996.csv',\n",
    "    'district_SOL_1997.csv',\n",
    "    'district_SOL_1998.csv',\n",
    "    'district_SOL_1999.csv',\n",
    "    'district_SOL_2000.csv',\n",
    "    'district_SOL_2001.csv',\n",
    "    'district_SOL_2002.csv',\n",
    "    'district_SOL_2003.csv',\n",
    "    'district_SOL_2004.csv',\n",
    "    'district_SOL_2005.csv',\n",
    "    'district_SOL_2006.csv',\n",
    "    'district_SOL_2007.csv',\n",
    "    'district_SOL_2008.csv',\n",
    "    'district_SOL_2009.csv',\n",
    "    'district_SOL_2010.csv',\n",
    "    'district_SOL_2011.csv',\n",
    "    'district_SOL_2012.csv',\n",
    "    'district_SOL_2013.csv',\n",
    "    'district_SOL_2014.csv',\n",
    "    'district_SOL_2015.csv',\n",
    "    'district_SOL_2016.csv',\n",
    "    'district_SOL_2017.csv',\n",
    "    'district_SOL_2018.csv',\n",
    "    'district_SOL_2019.csv',\n",
    "    'district_SOL_2020.csv',\n",
    "    'district_SOL_2021.csv',\n",
    "    'district_SOL_2022.csv'\n",
    "]\n",
    "\n",
    "# Initialize a dictionary to store the sum of values for each year\n",
    "sum_of_values = {}\n",
    "\n",
    "# Loop over each CSV file to compute the sum of the 3rd column\n",
    "for csv_file in csv_files:\n",
    "    # Get the full path to the CSV file\n",
    "    full_path = os.path.join(csv_folder, csv_file)\n",
    "    \n",
    "    # Extract the year from the filename\n",
    "    year = os.path.basename(csv_file).split('_')[2][:4]\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(full_path)\n",
    "    \n",
    "    # Assuming the 3rd column contains the SOL values\n",
    "    third_column = df.iloc[:, 2]  # This selects the 3rd column\n",
    "    \n",
    "    # Calculate the sum of the 3rd column\n",
    "    total_sum = third_column.sum()\n",
    "    \n",
    "    # Store the sum in the dictionary\n",
    "    sum_of_values[year] = total_sum\n",
    "\n",
    "    print(f\"Sum of values for {year}: {total_sum}\")\n",
    "\n",
    "# Optionally, save the results to a new CSV file\n",
    "sum_df = pd.DataFrame(list(sum_of_values.items()), columns=['Year', 'Sum_of_Lights'])\n",
    "sum_df.to_csv('sum_of_SOL_all_years.csv', index=False)\n",
    "\n",
    "print(\"Sum of lights for all years saved to 'sum_of_SOL_all_years.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your CSV files\n",
    "csv_folder = 'SOL data from 1992 to 2022 csv Indexed'\n",
    "\n",
    "# List of CSV files (from 1992 to 2022) in that folder\n",
    "csv_files = [\n",
    "    'district_SOL_1992.csv',\n",
    "    'district_SOL_1993.csv',\n",
    "    'district_SOL_1994.csv',\n",
    "    'district_SOL_1995.csv',\n",
    "    'district_SOL_1996.csv',\n",
    "    'district_SOL_1997.csv',\n",
    "    'district_SOL_1998.csv',\n",
    "    'district_SOL_1999.csv',\n",
    "    'district_SOL_2000.csv',\n",
    "    'district_SOL_2001.csv',\n",
    "    'district_SOL_2002.csv',\n",
    "    'district_SOL_2003.csv',\n",
    "    'district_SOL_2004.csv',\n",
    "    'district_SOL_2005.csv',\n",
    "    'district_SOL_2006.csv',\n",
    "    'district_SOL_2007.csv',\n",
    "    'district_SOL_2008.csv',\n",
    "    'district_SOL_2009.csv',\n",
    "    'district_SOL_2010.csv',\n",
    "    'district_SOL_2011.csv',\n",
    "    'district_SOL_2012.csv',\n",
    "    'district_SOL_2013.csv',\n",
    "    'district_SOL_2014.csv',\n",
    "    'district_SOL_2015.csv',\n",
    "    'district_SOL_2016.csv',\n",
    "    'district_SOL_2017.csv',\n",
    "    'district_SOL_2018.csv',\n",
    "    'district_SOL_2019.csv',\n",
    "    'district_SOL_2020.csv',\n",
    "    'district_SOL_2021.csv',\n",
    "    'district_SOL_2022.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "merged_df = None\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    # Get the full path to the CSV file\n",
    "    full_path = os.path.join(csv_folder, csv_file)\n",
    "    \n",
    "    # Extract the year from the filename\n",
    "    year = os.path.basename(csv_file).split('_')[2][:4]\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(full_path, index_col=0)\n",
    "    \n",
    "    # Check if the file has the expected number of columns\n",
    "    if df.shape[1] < 2:\n",
    "        print(f\"Skipping {csv_file}, it does not have enough columns.\")\n",
    "        continue\n",
    "\n",
    "    # Rename the 3rd column (SOL column) to represent the year (e.g., 'SOL_1992')\n",
    "    # Adjusting to make sure we rename the correct column if there are more or fewer columns\n",
    "    df = df.rename(columns={df.columns[1]: 'District', df.columns[-1]: f'SOL_{year}'})\n",
    "    \n",
    "    # If this is the first file, initialize the merged_df with the districts\n",
    "    if merged_df is None:\n",
    "        merged_df = df[['NAME_2', f'SOL_{year}']]\n",
    "    else:\n",
    "        # Merge the current year's data with the previously merged data\n",
    "        merged_df = pd.merge(merged_df, df[['NAME_2', f'SOL_{year}']], on='NAME_2', how='outer')\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_df.to_csv('combined_SOL_1992_to_2022.csv', index=True)\n",
    "\n",
    "print(\"All files combined and saved to 'combined_SOL_1992_to_2022.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08637a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed and saved to 'combined_SOL_1992_to_2022.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your CSV files\n",
    "csv_folder = 'SOL data from 1992 to 2022 csv Indexed'\n",
    "\n",
    "# List of CSV files (from 1992 to 2022) in that folder\n",
    "csv_files = [\n",
    "    'district_SOL_1992.csv',\n",
    "    'district_SOL_1993.csv',\n",
    "    'district_SOL_1994.csv',\n",
    "    'district_SOL_1995.csv',\n",
    "    'district_SOL_1996.csv',\n",
    "    'district_SOL_1997.csv',\n",
    "    'district_SOL_1998.csv',\n",
    "    'district_SOL_1999.csv',\n",
    "    'district_SOL_2000.csv',\n",
    "    'district_SOL_2001.csv',\n",
    "    'district_SOL_2002.csv',\n",
    "    'district_SOL_2003.csv',\n",
    "    'district_SOL_2004.csv',\n",
    "    'district_SOL_2005.csv',\n",
    "    'district_SOL_2006.csv',\n",
    "    'district_SOL_2007.csv',\n",
    "    'district_SOL_2008.csv',\n",
    "    'district_SOL_2009.csv',\n",
    "    'district_SOL_2010.csv',\n",
    "    'district_SOL_2011.csv',\n",
    "    'district_SOL_2012.csv',\n",
    "    'district_SOL_2013.csv',\n",
    "    'district_SOL_2014.csv',\n",
    "    'district_SOL_2015.csv',\n",
    "    'district_SOL_2016.csv',\n",
    "    'district_SOL_2017.csv',\n",
    "    'district_SOL_2018.csv',\n",
    "    'district_SOL_2019.csv',\n",
    "    'district_SOL_2020.csv',\n",
    "    'district_SOL_2021.csv',\n",
    "    'district_SOL_2022.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "final_output_file = 'combined_SOL_1992_to_2022.csv'\n",
    "\n",
    "# Initialize the CSV where the final results will be stored\n",
    "first_file = True\n",
    "\n",
    "# Loop through each CSV file and process them one by one\n",
    "for csv_file in csv_files:\n",
    "    # Get the full path to the CSV file\n",
    "    full_path = os.path.join(csv_folder, csv_file)\n",
    "    \n",
    "    # Extract the year from the filename\n",
    "    year = os.path.basename(csv_file).split('_')[2][:4]\n",
    "    \n",
    "    # Read the CSV file, processing in chunks if necessary\n",
    "    # We'll use a smaller chunk size if the CSV is large\n",
    "    for chunk in pd.read_csv(full_path, chunksize=1000):\n",
    "        # Check if the file has the expected number of columns\n",
    "        if chunk.shape[1] < 2:\n",
    "            print(f\"Skipping {csv_file}, it does not have enough columns.\")\n",
    "            continue\n",
    "\n",
    "        # Rename the 3rd column to represent the year (e.g., 'SOL_1992')\n",
    "        chunk = chunk.rename(columns={chunk.columns[1]: 'District', chunk.columns[-1]: f'SOL_{year}'})\n",
    "\n",
    "        # Write to file, append if this is not the first time writing\n",
    "        if first_file:\n",
    "            chunk.to_csv(final_output_file, mode='w', index=False)\n",
    "            first_file = False\n",
    "        else:\n",
    "            chunk.to_csv(final_output_file, mode='a', header=False, index=False)\n",
    "\n",
    "print(f\"All files processed and saved to '{final_output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a0a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed and saved to 'combined_SOL_1992_to_2022.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your CSV files\n",
    "csv_folder = 'SOL data from 1992 to 2022 csv Indexed'\n",
    "\n",
    "# List of CSV files (from 1992 to 2022) in that folder\n",
    "csv_files = [\n",
    "    'district_SOL_1992.csv',\n",
    "    'district_SOL_1993.csv',\n",
    "    'district_SOL_1994.csv',\n",
    "    'district_SOL_1995.csv',\n",
    "    'district_SOL_1996.csv',\n",
    "    'district_SOL_1997.csv',\n",
    "    'district_SOL_1998.csv',\n",
    "    'district_SOL_1999.csv',\n",
    "    'district_SOL_2000.csv',\n",
    "    'district_SOL_2001.csv',\n",
    "    'district_SOL_2002.csv',\n",
    "    'district_SOL_2003.csv',\n",
    "    'district_SOL_2004.csv',\n",
    "    'district_SOL_2005.csv',\n",
    "    'district_SOL_2006.csv',\n",
    "    'district_SOL_2007.csv',\n",
    "    'district_SOL_2008.csv',\n",
    "    'district_SOL_2009.csv',\n",
    "    'district_SOL_2010.csv',\n",
    "    'district_SOL_2011.csv',\n",
    "    'district_SOL_2012.csv',\n",
    "    'district_SOL_2013.csv',\n",
    "    'district_SOL_2014.csv',\n",
    "    'district_SOL_2015.csv',\n",
    "    'district_SOL_2016.csv',\n",
    "    'district_SOL_2017.csv',\n",
    "    'district_SOL_2018.csv',\n",
    "    'district_SOL_2019.csv',\n",
    "    'district_SOL_2020.csv',\n",
    "    'district_SOL_2021.csv',\n",
    "    'district_SOL_2022.csv'\n",
    "]\n",
    "\n",
    "# Output file for the final combined result\n",
    "final_output_file = 'combined_SOL_1992_to_2022.csv'\n",
    "\n",
    "# Initialize a flag to write the header only once\n",
    "first_file = True\n",
    "\n",
    "# Loop through each CSV file and process them one by one\n",
    "for csv_file in csv_files:\n",
    "    # Get the full path to the CSV file\n",
    "    full_path = os.path.join(csv_folder, csv_file)\n",
    "    \n",
    "    # Extract the year from the filename\n",
    "    year = os.path.basename(csv_file).split('_')[2][:4]\n",
    "    \n",
    "    # Read the CSV file in smaller chunks if necessary to avoid memory issues\n",
    "    for chunk in pd.read_csv(full_path, chunksize=1000):\n",
    "        # Check if the file has the expected number of columns\n",
    "        if chunk.shape[1] < 2:\n",
    "            print(f\"Skipping {csv_file}, it does not have enough columns.\")\n",
    "            continue\n",
    "\n",
    "        # Rename the last column (SOL column) to represent the year (e.g., 'SOL_1992')\n",
    "        chunk = chunk.rename(columns={chunk.columns[1]: 'District', chunk.columns[-1]: f'SOL_{year}'})\n",
    "\n",
    "        # If this is the first file, initialize the output with header\n",
    "        if first_file:\n",
    "            chunk.to_csv(final_output_file, mode='w', index=False)\n",
    "            first_file = False\n",
    "        else:\n",
    "            # Otherwise, append the data without writing the header again\n",
    "            chunk.to_csv(final_output_file, mode='a', header=False, index=False)\n",
    "\n",
    "print(f\"All files processed and saved to '{final_output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your CSV files\n",
    "csv_folder = 'SOL data from 1992 to 2022 csv Indexed'\n",
    "\n",
    "# List of CSV files (from 1992 to 2022) in that folder\n",
    "csv_files = [\n",
    "    'district_SOL_1992.csv',\n",
    "    'district_SOL_1993.csv',\n",
    "    'district_SOL_1994.csv',\n",
    "    'district_SOL_1995.csv',\n",
    "    'district_SOL_1996.csv',\n",
    "    'district_SOL_1997.csv',\n",
    "    'district_SOL_1998.csv',\n",
    "    'district_SOL_1999.csv',\n",
    "    'district_SOL_2000.csv',\n",
    "    'district_SOL_2001.csv',\n",
    "    'district_SOL_2002.csv',\n",
    "    'district_SOL_2003.csv',\n",
    "    'district_SOL_2004.csv',\n",
    "    'district_SOL_2005.csv',\n",
    "    'district_SOL_2006.csv',\n",
    "    'district_SOL_2007.csv',\n",
    "    'district_SOL_2008.csv',\n",
    "    'district_SOL_2009.csv',\n",
    "    'district_SOL_2010.csv',\n",
    "    'district_SOL_2011.csv',\n",
    "    'district_SOL_2012.csv',\n",
    "    'district_SOL_2013.csv',\n",
    "    'district_SOL_2014.csv',\n",
    "    'district_SOL_2015.csv',\n",
    "    'district_SOL_2016.csv',\n",
    "    'district_SOL_2017.csv',\n",
    "    'district_SOL_2018.csv',\n",
    "    'district_SOL_2019.csv',\n",
    "    'district_SOL_2020.csv',\n",
    "    'district_SOL_2021.csv',\n",
    "    'district_SOL_2022.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    # Get the full path to the CSV file\n",
    "    full_path = os.path.join(csv_folder, csv_file)\n",
    "    \n",
    "    # Extract the year from the filename\n",
    "    year = os.path.basename(csv_file).split('_')[2][:4]\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(full_path, index_col=0)\n",
    "    \n",
    "    # Check if the file has the expected number of columns\n",
    "    if df.shape[1] < 2:\n",
    "        print(f\"Skipping {csv_file}, it does not have enough columns.\")\n",
    "        continue\n",
    "\n",
    "    # Rename the last column (SOL column) to represent the year (e.g., 'SOL_1992')\n",
    "    df = df.rename(columns={df.columns[1]: 'District', df.columns[-1]: f'SOL_{year}'})\n",
    "\n",
    "    # Merge the current year's data with the previously merged data\n",
    "    if merged_df.empty:\n",
    "        merged_df = df[['NAME_2', f'SOL_{year}']]  # Start with the first year\n",
    "    else:\n",
    "        # Merge on 'District' column\n",
    "        merged_df = pd.merge(merged_df, df[['NAME_2', f'SOL_{year}']], on='NAME_2', how='outer')\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_df.to_csv('combined_SOL_1992_to_2022.csv', index=False)\n",
    "\n",
    "print(\"All files combined and saved to 'combined_SOL_1992_to_2022.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816bb1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reshaped and saved to reshaped_output_file.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "input_file = 'combined_SOL_1992_to_2022 Vertically.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Number of rows after which we want to split the data into new columns\n",
    "rows_per_block = 676\n",
    "\n",
    "# Number of columns we have in the original data (3 in your case)\n",
    "cols = df.shape[1]\n",
    "\n",
    "# Initialize an empty list to store the reshaped data\n",
    "reshaped_data = []\n",
    "\n",
    "# Loop through the dataframe in chunks of 676 rows\n",
    "for start in range(0, len(df), rows_per_block):\n",
    "    # Extract a chunk of 676 rows\n",
    "    chunk = df.iloc[start:start + rows_per_block].reset_index(drop=True)\n",
    "    \n",
    "    # Append the chunk to the reshaped_data list\n",
    "    reshaped_data.append(chunk)\n",
    "\n",
    "# Concatenate the reshaped chunks along the columns axis\n",
    "reshaped_df = pd.concat(reshaped_data, axis=1)\n",
    "\n",
    "# Generate new column names\n",
    "new_columns = []\n",
    "for i in range(len(reshaped_data)):\n",
    "    new_columns.extend([f'Col_A_Block_{i+1}', f'Col_B_Block_{i+1}', f'Col_C_Block_{i+1}'])\n",
    "\n",
    "# Assign new column names to the reshaped dataframe\n",
    "reshaped_df.columns = new_columns\n",
    "\n",
    "# Save the reshaped dataframe to a new CSV file\n",
    "output_file = 'reshaped_output_file.csv'\n",
    "reshaped_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data reshaped and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d4110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified CSV saved to modified_output_file.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = 'reshaped_output_file.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Keep only Col_A_Block_1 and Col_B_Block_1, and remove other Col_A_Block_X and Col_B_Block_X\n",
    "columns_to_keep = ['Col_A_Block_1', 'Col_B_Block_1']  # Keep the first occurrences\n",
    "\n",
    "# Loop through and keep all Col_C_Block_X columns\n",
    "for i in range(1, 32):  # Since you have Col_C_Block_1 to Col_C_Block_31\n",
    "    columns_to_keep.append(f'Col_C_Block_{i}')\n",
    "\n",
    "# Select only the columns we need\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Rename Col_C_Block_X to the respective year (1992, 1993, etc.)\n",
    "year = 1992\n",
    "new_column_names = {\n",
    "    f'Col_C_Block_{i}': str(year + (i - 1)) for i in range(1, 32)  # Map Col_C_Block_X to years\n",
    "}\n",
    "df = df.rename(columns=new_column_names)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file = 'modified_output_file.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Modified CSV saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b73487b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
